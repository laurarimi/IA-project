{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from utils import *\n",
    "\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 66\n",
    "BATCH_SIZE = 32\n",
    "CATEGORIES = \"sadness,joy,anger,fear,surprise,neutral\".split(',')\n",
    "\n",
    "\n",
    "def tokenize(sentences, max_length=MAX_SEQUENCE_LENGTH, padding='max_length'):\n",
    "\n",
    "    return tokenizer(\n",
    "        sentences,\n",
    "        truncation=True,\n",
    "        padding=padding,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "def decode(tokens):\n",
    "    return tokenizer.decode(tokens)\n",
    "\n",
    "def to_tensor(data, label = []):\n",
    "    return tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenize(data)),  # Convert BatchEncoding instance to dictionary\n",
    "    label\n",
    "    )).batch(BATCH_SIZE).prefetch(1)\n",
    "\n",
    "def predict(str,model):\n",
    "    str = to_tensor(str)\n",
    "    model.predict(str)\n",
    "\n",
    "def predice(array,model):\n",
    "\n",
    "    array = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenize(array)),\n",
    "    )).batch(BATCH_SIZE).prefetch(1)\n",
    "    df = pd.DataFrame(columns=CATEGORIES,data=model.predict(array))\n",
    "    #reorder the columns in the following order: surprise, anger, fear, sadness, joy, neutral\n",
    "    df = df[['surprise','anger','fear','sadness','joy','neutral']]\n",
    "    return df, df.values\n",
    "\n",
    "\n",
    "\n",
    "NLP_model =  tf.keras.models.load_model('C:\\\\Users\\\\mario\\\\PROYECTO_IA\\\\IA-project\\\\Notebooks\\\\MARIO\\\\SentimentAnalysis.hdf5', custom_objects={'TFDistilBertModel': TFDistilBertModel})\n",
    "# audio_model = keras.models.load_model('C:\\\\Users\\\\mario\\\\PROYECTO_IA\\\\IA-project\\\\Notebooks\\\\MARIO\\\\model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording Audio\n",
      "Finished recording\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\envs\\CAPSTONE_PROJECT\\lib\\site-packages\\whisper\\transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "\n",
      "  0%|          | 0/800 [00:00<?, ?frames/s]\n",
      " 88%|████████▊ | 700/800 [00:06<00:00, 115.62frames/s]\n",
      "100%|██████████| 800/800 [00:09<00:00, 78.09frames/s] \n",
      "100%|██████████| 800/800 [00:09<00:00, 85.35frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I didn't expect this from you, you destroyed me, you had to spend the workfor the rest of the day.\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "   surprise    anger      fear  sadness       joy   neutral\n",
      "0  0.044827  0.43381  0.050005  0.33972  0.006234  0.125404\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fs = 44100  # Sample rate\n",
    "seconds = 8  # Duration of recording\n",
    "\n",
    "myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=2)\n",
    "print(\"Recording Audio\")\n",
    "sd.wait()  # Wait until recording is finished\n",
    "print(\"Finished recording\")\n",
    "write('output.wav', fs, myrecording)  # Save as WAV file \n",
    "\n",
    "!whisper --task translate --language es --model base --verbose False output.wav\n",
    "\n",
    "with open('output.wav.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "\n",
    "print(data)\n",
    "df, inputs = predice(data,NLP_model)\n",
    "\n",
    "inputs = inputs[0]\n",
    "\n",
    "generate_sound(get_notes(inputs))\n",
    "print(df)\n",
    "\n",
    "filename = 'PRUEBAS2.wav'\n",
    "# Extract data and sampling rate from file\n",
    "data, fs = sf.read(filename, dtype='float32')  \n",
    "sd.play(data, fs)\n",
    "status = sd.wait()  # Wait until file is done playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data of audio_test.wav.txt file\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAPSTONE_PROJECT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "528f1c4a8f5c6e5cd5d8d78b4daa41b3ade1cbafba6a160042eee37a16d4e513"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
