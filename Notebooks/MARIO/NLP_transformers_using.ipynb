{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 66\n",
    "BATCH_SIZE = 32\n",
    "CATEGORIES = \"sadness,joy,anger,fear,surprise\".split(',')\n",
    "\n",
    "\n",
    "def tokenize(sentences, max_length=MAX_SEQUENCE_LENGTH, padding='max_length'):\n",
    "\n",
    "    return tokenizer(\n",
    "        sentences,\n",
    "        truncation=True,\n",
    "        padding=padding,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "def decode(tokens):\n",
    "    return tokenizer.decode(tokens)\n",
    "def to_tensor(data, label = []):\n",
    "    return tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenize(data)),  # Convert BatchEncoding instance to dictionary\n",
    "    label\n",
    "    )).batch(BATCH_SIZE).prefetch(1)\n",
    "def predict(str,model):\n",
    "    str = to_tensor(str)\n",
    "    model.predict(str)\n",
    "def predice(array,model):\n",
    "    array = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenize(array)),\n",
    "    )).batch(BATCH_SIZE).prefetch(1)\n",
    "    return pd.DataFrame(columns=CATEGORIES,data=model.predict(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\mario\\anaconda3\\envs\\SOLVING_PROBLEMS\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('SentimentAnalysis.hdf5', custom_objects={'TFDistilBertModel': TFDistilBertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.993538</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sadness       joy     anger      fear  surprise\n",
       "0  0.003098  0.993538  0.002981  0.000144  0.000239"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predice('I love you',new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model('medium')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\whisper\\transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\Scripts\\whisper.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\whisper\\transcribe.py\", line 307, in cli\n",
      "    result = transcribe(model, audio_path, temperature=temperature, **args)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\whisper\\transcribe.py\", line 84, in transcribe\n",
      "    mel = log_mel_spectrogram(audio)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\whisper\\audio.py\", line 111, in log_mel_spectrogram\n",
      "    audio = load_audio(audio)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\whisper\\audio.py\", line 42, in load_audio\n",
      "    ffmpeg.input(file, threads=0)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\ffmpeg\\_run.py\", line 313, in run\n",
      "    process = run_async(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\ffmpeg\\_run.py\", line 284, in run_async\n",
      "    return subprocess.Popen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\subprocess.py\", line 951, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\subprocess.py\", line 1420, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "FileNotFoundError: [WinError 2] El sistema no puede encontrar el archivo especificado\n"
     ]
    }
   ],
   "source": [
    "!whisper \"prueba.mp3\" --model medium --language es --task transcribe --device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\mario\\appdata\\local\\temp\\pip-req-build-hqz17knx\n",
      "  Resolved https://github.com/openai/whisper.git to commit eff383b27b783e280c089475852ba83f20f64998\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from whisper==1.0) (1.21.5)\n",
      "Requirement already satisfied: torch in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from whisper==1.0) (1.13.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from whisper==1.0) (4.64.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from whisper==1.0) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.19.0 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from whisper==1.0) (4.24.0)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from whisper==1.0) (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.18.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (0.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (3.6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from tqdm->whisper==1.0) (0.4.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from torch->whisper==1.0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\mario\\AppData\\Local\\Temp\\pip-req-build-hqz17knx'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jiwer in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: levenshtein==0.20.2 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from jiwer) (0.20.2)\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from levenshtein==0.20.2->jiwer) (2.13.3)\n"
     ]
    }
   ],
   "source": [
    "#@title ⚙️ Ejecutar esta celda para instalar las librería.\n",
    "\"\"\"\n",
    "To write this piece of code I took inspiration/code from a lot of places.\n",
    "It was late night, so I'm not sure how much I created or just copied o.O\n",
    "Here are some of the possible references:\n",
    "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
    "https://stackoverflow.com/a/18650249\n",
    "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
    "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
    "https://stackoverflow.com/a/49019356\n",
    "\"\"\"\n",
    "\n",
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install jiwer\n",
    "\n",
    "from IPython.display import HTML, Audio\n",
    "from js2py import eval_js\n",
    "from base64 import b64decode\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read as wav_read\n",
    "import io\n",
    "import ffmpeg\n",
    "\n",
    "AUDIO_HTML = \"\"\"\n",
    "<script>\n",
    "var my_div = document.createElement(\"DIV\");\n",
    "var my_p = document.createElement(\"P\");\n",
    "var my_btn = document.createElement(\"BUTTON\");\n",
    "var t = document.createTextNode(\"Press to start recording\");\n",
    "\n",
    "my_btn.appendChild(t);\n",
    "//my_p.appendChild(my_btn);\n",
    "my_div.appendChild(my_btn);\n",
    "document.body.appendChild(my_div);\n",
    "\n",
    "var base64data = 0;\n",
    "var reader;\n",
    "var recorder, gumStream;\n",
    "var recordButton = my_btn;\n",
    "\n",
    "var handleSuccess = function(stream) {\n",
    "  gumStream = stream;\n",
    "  var options = {\n",
    "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
    "    mimeType : 'audio/webm;codecs=opus'\n",
    "    //mimeType : 'audio/webm;codecs=pcm'\n",
    "  };            \n",
    "  //recorder = new MediaRecorder(stream, options);\n",
    "  recorder = new MediaRecorder(stream);\n",
    "  recorder.ondataavailable = function(e) {            \n",
    "    var url = URL.createObjectURL(e.data);\n",
    "    var preview = document.createElement('audio');\n",
    "    preview.controls = true;\n",
    "    preview.src = url;\n",
    "    document.body.appendChild(preview);\n",
    "\n",
    "    reader = new FileReader();\n",
    "    reader.readAsDataURL(e.data); \n",
    "    reader.onloadend = function() {\n",
    "      base64data = reader.result;\n",
    "      //console.log(\"Inside FileReader:\" + base64data);\n",
    "    }\n",
    "  };\n",
    "  recorder.start();\n",
    "  };\n",
    "\n",
    "recordButton.innerText = \"Recording... press to stop\";\n",
    "\n",
    "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
    "\n",
    "\n",
    "function toggleRecording() {\n",
    "  if (recorder && recorder.state == \"recording\") {\n",
    "      recorder.stop();\n",
    "      gumStream.getAudioTracks()[0].stop();\n",
    "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
    "  }\n",
    "}\n",
    "\n",
    "// https://stackoverflow.com/a/951057\n",
    "function sleep(ms) {\n",
    "  return new Promise(resolve => setTimeout(resolve, ms));\n",
    "}\n",
    "\n",
    "var data = new Promise(resolve=>{\n",
    "//recordButton.addEventListener(\"click\", toggleRecording);\n",
    "recordButton.onclick = ()=>{\n",
    "toggleRecording()\n",
    "\n",
    "sleep(2000).then(() => {\n",
    "  // wait 2000ms for the data to be available...\n",
    "  // ideally this should use something like await...\n",
    "  //console.log(\"Inside data:\" + base64data)\n",
    "  resolve(base64data.toString())\n",
    "\n",
    "});\n",
    "\n",
    "}\n",
    "});\n",
    "      \n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "def get_audio():\n",
    "  display(HTML(AUDIO_HTML))\n",
    "  data = eval_js(\"data\")\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  \n",
    "  process = (ffmpeg\n",
    "    .input('pipe:0')\n",
    "    .output('pipe:1', format='wav')\n",
    "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
    "  )\n",
    "  output, err = process.communicate(input=binary)\n",
    "  \n",
    "  riff_chunk_size = len(output) - 8\n",
    "  # Break up the chunk size into four bytes, held in b.\n",
    "  q = riff_chunk_size\n",
    "  b = []\n",
    "  for i in range(4):\n",
    "      q, r = divmod(q, 256)\n",
    "      b.append(r)\n",
    "\n",
    "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
    "  riff = output[:4] + bytes(b) + output[8:]\n",
    "\n",
    "  sr, audio = wav_read(io.BytesIO(riff))\n",
    "\n",
    "  return audio, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\whisper\\transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\Scripts\\whisper.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\whisper\\transcribe.py\", line 307, in cli\n",
      "    result = transcribe(model, audio_path, temperature=temperature, **args)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\whisper\\transcribe.py\", line 84, in transcribe\n",
      "    mel = log_mel_spectrogram(audio)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\whisper\\audio.py\", line 111, in log_mel_spectrogram\n",
      "    audio = load_audio(audio)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\whisper\\audio.py\", line 42, in load_audio\n",
      "    ffmpeg.input(file, threads=0)\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\ffmpeg\\_run.py\", line 313, in run\n",
      "    process = run_async(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\site-packages\\ffmpeg\\_run.py\", line 284, in run_async\n",
      "    return subprocess.Popen(\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\subprocess.py\", line 951, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\mario\\anaconda3\\envs\\entornoGPU\\lib\\subprocess.py\", line 1420, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "FileNotFoundError: [WinError 2] El sistema no puede encontrar el archivo especificado\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import whisper\n",
    "from scipy.io.wavfile import write\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "!whisper \"C:/Users/mario/prueba.mp3\" --task transcribe --model medium --language es\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge ffmpeg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('SOLVING_PROBLEMS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bebf755d34ec7da39309966eb65add46c5b6bb4f82fc8a617dbbecd2ed6c0695"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
