{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 66\n",
    "BATCH_SIZE = 32\n",
    "CATEGORIES = \"sadness,joy,anger,fear,surprise\".split(',')\n",
    "\n",
    "\n",
    "def tokenize(sentences, max_length=MAX_SEQUENCE_LENGTH, padding='max_length'):\n",
    "\n",
    "    return tokenizer(\n",
    "        sentences,\n",
    "        truncation=True,\n",
    "        padding=padding,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "\n",
    "def decode(tokens):\n",
    "    return tokenizer.decode(tokens)\n",
    "def to_tensor(data, label = []):\n",
    "    return tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenize(data)),  # Convert BatchEncoding instance to dictionary\n",
    "    label\n",
    "    )).batch(BATCH_SIZE).prefetch(1)\n",
    "def predict(str,model):\n",
    "    str = to_tensor(str)\n",
    "    model.predict(str)\n",
    "def predice(array,model):\n",
    "    array = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(tokenize(array)),\n",
    "    )).batch(BATCH_SIZE).prefetch(1)\n",
    "    return pd.DataFrame(columns=CATEGORIES,data=model.predict(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('SentimentAnalysis.hdf5', custom_objects={'TFDistilBertModel': TFDistilBertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 413ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sadness</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009263</td>\n",
       "      <td>0.00062</td>\n",
       "      <td>0.934321</td>\n",
       "      <td>0.05558</td>\n",
       "      <td>0.000217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sadness      joy     anger     fear  surprise\n",
       "0  0.009263  0.00062  0.934321  0.05558  0.000217"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predice('',new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to c:\\users\\mario\\appdata\\local\\temp\\pip-req-build-5_27e0iy\n",
      "  Resolved https://github.com/openai/whisper.git to commit eff383b27b783e280c089475852ba83f20f64998\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from whisper==1.0) (1.21.5)\n",
      "Requirement already satisfied: torch in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from whisper==1.0) (1.13.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from whisper==1.0) (4.64.1)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-9.0.0-py3-none-any.whl (52 kB)\n",
      "     -------------------------------------- 52.8/52.8 kB 905.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: transformers>=4.19.0 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from whisper==1.0) (4.24.0)\n",
      "Collecting ffmpeg-python==0.2.0\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting future\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (0.11.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from tqdm->whisper==1.0) (0.4.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from torch->whisper==1.0) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mario\\anaconda3\\envs\\entornogpu\\lib\\site-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.4)\n",
      "Building wheels for collected packages: whisper, future\n",
      "  Building wheel for whisper (setup.py): started\n",
      "  Building wheel for whisper (setup.py): finished with status 'done'\n",
      "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1187113 sha256=530b90c0b6c76ea0791da4da7d38fde83cb17c9b6b837d9400257cbee3c53b6d\n",
      "  Stored in directory: C:\\Users\\mario\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-7h9rmcgk\\wheels\\fe\\03\\29\\e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491086 sha256=d939abedebfd25ed4e8a20a4ce484b3be88cbfef948ef15786e7531cb2af8b7e\n",
      "  Stored in directory: c:\\users\\mario\\appdata\\local\\pip\\cache\\wheels\\96\\66\\19\\2de75120f5d0bc185e9d16cf0fd223d8471ed025de08e45867\n",
      "Successfully built whisper future\n",
      "Installing collected packages: more-itertools, future, ffmpeg-python, whisper\n",
      "Successfully installed ffmpeg-python-0.2.0 future-0.18.2 more-itertools-9.0.0 whisper-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git 'C:\\Users\\mario\\AppData\\Local\\Temp\\pip-req-build-5_27e0iy'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-2.5.1-py3-none-any.whl (15 kB)\n",
      "Collecting levenshtein==0.20.2\n",
      "  Downloading Levenshtein-0.20.2-cp39-cp39-win_amd64.whl (182 kB)\n",
      "     -------------------------------------- 182.5/182.5 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting rapidfuzz<3.0.0,>=2.3.0\n",
      "  Downloading rapidfuzz-2.13.3-cp39-cp39-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 16.2 MB/s eta 0:00:00\n",
      "Installing collected packages: rapidfuzz, levenshtein, jiwer\n",
      "Successfully installed jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.13.3\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25176\\2607905435.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0meval_js\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbase64\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "#@title ⚙️ Ejecutar esta celda para instalar las librería.\n",
    "\"\"\"\n",
    "To write this piece of code I took inspiration/code from a lot of places.\n",
    "It was late night, so I'm not sure how much I created or just copied o.O\n",
    "Here are some of the possible references:\n",
    "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
    "https://stackoverflow.com/a/18650249\n",
    "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
    "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
    "https://stackoverflow.com/a/49019356\n",
    "\"\"\"\n",
    "\n",
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install jiwer\n",
    "\n",
    "from IPython.display import HTML, Audio\n",
    "from base64 import b64decode\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read as wav_read\n",
    "import io\n",
    "import ffmpeg\n",
    "\n",
    "AUDIO_HTML = \"\"\"\n",
    "<script>\n",
    "var my_div = document.createElement(\"DIV\");\n",
    "var my_p = document.createElement(\"P\");\n",
    "var my_btn = document.createElement(\"BUTTON\");\n",
    "var t = document.createTextNode(\"Press to start recording\");\n",
    "\n",
    "my_btn.appendChild(t);\n",
    "//my_p.appendChild(my_btn);\n",
    "my_div.appendChild(my_btn);\n",
    "document.body.appendChild(my_div);\n",
    "\n",
    "var base64data = 0;\n",
    "var reader;\n",
    "var recorder, gumStream;\n",
    "var recordButton = my_btn;\n",
    "\n",
    "var handleSuccess = function(stream) {\n",
    "  gumStream = stream;\n",
    "  var options = {\n",
    "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
    "    mimeType : 'audio/webm;codecs=opus'\n",
    "    //mimeType : 'audio/webm;codecs=pcm'\n",
    "  };            \n",
    "  //recorder = new MediaRecorder(stream, options);\n",
    "  recorder = new MediaRecorder(stream);\n",
    "  recorder.ondataavailable = function(e) {            \n",
    "    var url = URL.createObjectURL(e.data);\n",
    "    var preview = document.createElement('audio');\n",
    "    preview.controls = true;\n",
    "    preview.src = url;\n",
    "    document.body.appendChild(preview);\n",
    "\n",
    "    reader = new FileReader();\n",
    "    reader.readAsDataURL(e.data); \n",
    "    reader.onloadend = function() {\n",
    "      base64data = reader.result;\n",
    "      //console.log(\"Inside FileReader:\" + base64data);\n",
    "    }\n",
    "  };\n",
    "  recorder.start();\n",
    "  };\n",
    "\n",
    "recordButton.innerText = \"Recording... press to stop\";\n",
    "\n",
    "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
    "\n",
    "\n",
    "function toggleRecording() {\n",
    "  if (recorder && recorder.state == \"recording\") {\n",
    "      recorder.stop();\n",
    "      gumStream.getAudioTracks()[0].stop();\n",
    "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
    "  }\n",
    "}\n",
    "\n",
    "// https://stackoverflow.com/a/951057\n",
    "function sleep(ms) {\n",
    "  return new Promise(resolve => setTimeout(resolve, ms));\n",
    "}\n",
    "\n",
    "var data = new Promise(resolve=>{\n",
    "//recordButton.addEventListener(\"click\", toggleRecording);\n",
    "recordButton.onclick = ()=>{\n",
    "toggleRecording()\n",
    "\n",
    "sleep(2000).then(() => {\n",
    "  // wait 2000ms for the data to be available...\n",
    "  // ideally this should use something like await...\n",
    "  //console.log(\"Inside data:\" + base64data)\n",
    "  resolve(base64data.toString())\n",
    "\n",
    "});\n",
    "\n",
    "}\n",
    "});\n",
    "      \n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "def get_audio():\n",
    "  display(HTML(AUDIO_HTML))\n",
    "  data = eval_js(\"data\")\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  \n",
    "  process = (ffmpeg\n",
    "    .input('pipe:0')\n",
    "    .output('pipe:1', format='wav')\n",
    "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
    "  )\n",
    "  output, err = process.communicate(input=binary)\n",
    "  \n",
    "  riff_chunk_size = len(output) - 8\n",
    "  # Break up the chunk size into four bytes, held in b.\n",
    "  q = riff_chunk_size\n",
    "  b = []\n",
    "  for i in range(4):\n",
    "      q, r = divmod(q, 256)\n",
    "      b.append(r)\n",
    "\n",
    "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
    "  riff = output[:4] + bytes(b) + output[8:]\n",
    "\n",
    "  sr, audio = wav_read(io.BytesIO(riff))\n",
    "\n",
    "  return audio, sr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('entornoGPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01b34738b84580687c62fc537ad80fea38859410cb32558d1c957df9f2f9e3fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
